{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33d8e79",
   "metadata": {},
   "source": [
    "# 리플렉션\n",
    "\n",
    "[Reflexion](https://arxiv.org/abs/2303.11366) 논문은 언어 피드백과 스스로의 반성을 통해 학습하도록 설계된 아키텍처입니다. 에이전트는 작업에 대한 자신의 응답을 명시적으로 비판하여 더 높은 품질의 최종 답변을 생성하지만, 그만큼 실행 시간이 길어집니다.\n",
    "\n",
    "![reflexion diagram](attachment:2f424259-8d89-4f4e-94c4-d668a36d8ca2.png)\n",
    "\n",
    "논문에서는 세 가지 주요 구성 요소를 설명합니다:\n",
    "\n",
    "1. 자기 반성을 수행하는 액터(에이전트)\n",
    "2. 과제별 외부 평가자(예: 코드 컴파일 단계)\n",
    "3. (1)의 반성을 저장하는 에피소드 메모리\n",
    "\n",
    "공개된 코드에서는 마지막 두 구성 요소가 과제에 매우 특화되어 있으므로, 이 노트북에서는 LangGraph를 사용해 **액터** 부분을 구현합니다.\n",
    "\n",
    "그래프 정의 부분으로 바로 가려면 아래의 [그래프 구성](#Construct-Graph) 섹션을 참고하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fa4bfd",
   "metadata": {},
   "source": [
    "## 환경 설정\n",
    "\n",
    "`langgraph`(프레임워크), `langchain_openai`(LLM용), 그리고 `langchain` + `tavily-python`(검색 엔진용)을 설치합니다.\n",
    "\n",
    "이 예제에서는 tavily 검색을 도구로 사용합니다. [여기](https://app.tavily.com/sign-in)에서 API 키를 받거나 원하는 다른 도구로 교체해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U --quiet langgraph langchain_anthropic tavily-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f91306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_if_undefined(var: str) -> None:\n",
    "    if os.environ.get(var):\n",
    "        return\n",
    "    os.environ[var] = getpass.getpass(var)\n",
    "\n",
    "\n",
    "_set_if_undefined(\"ANTHROPIC_API_KEY\")\n",
    "_set_if_undefined(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c08d5c",
   "metadata": {},
   "source": [
    "<div class=\"admonition tip\">\n",
    "    <p class=\"admonition-title\">LangGraph 개발을 위한 <a href=\"https://smith.langchain.com\">LangSmith</a> 설정</p>\n",
    "    <p style=\"padding-top: 5px;\">\n",
    "        LangSmith에 가입하면 LangGraph 프로젝트의 문제를 빠르게 파악하고 성능을 향상시킬 수 있습니다. 추적 데이터를 활용해 디버그, 테스트, 모니터링할 수 있으니 <a href=\"https://docs.smith.langchain.com\">여기</a>에서 시작해 보세요.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "### LLM 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d2f015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "# You could also use OpenAI or another provider\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01f2656",
   "metadata": {},
   "source": [
    "## 반성 기능을 갖춘 액터\n",
    "\n",
    "Reflexion의 핵심 요소는 \"액터\"로, 자신이 생성한 답변을 되돌아보고 자기 비판을 통해 다시 실행하며 성능을 향상시키는 에이전트입니다. 주요 하위 구성 요소는 다음과 같습니다.\n",
    "1. 도구 실행\n",
    "2. 초기 응답자: 초기 답변 생성(및 자기 반성)\n",
    "3. 수정자: 이전 반성을 바탕으로 다시 답변\n",
    "\n",
    "먼저 도구 실행 컨텍스트를 정의해 보겠습니다.\n",
    "\n",
    "#### Construct tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddd0a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "\n",
    "search = TavilySearchAPIWrapper()\n",
    "tavily_tool = TavilySearchResults(api_wrapper=search, max_results=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f2066",
   "metadata": {},
   "source": [
    "#### 초기 응답자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e488a72",
   "metadata": {},
   "source": [
    "<div class=\"admonition note\">\n",
    "    <p class=\"admonition-title\">LangChain에서 Pydantic 사용</p>\n",
    "    <p>\n",
    "        이 노트북은 Pydantic v2 <code>BaseModel</code>을 사용하므로 <code>langchain-core >= 0.3</code> 버전이 필요합니다. 만약 <code>langchain-core < 0.3</code>을 사용하면 Pydantic v1과 v2 <code>BaseModel</code>이 혼합되어 오류가 발생합니다.\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c522154",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from pydantic import ValidationError\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Reflection(BaseModel):\n",
    "    missing: str = Field(description=\"Critique of what is missing.\")\n",
    "    superfluous: str = Field(description=\"Critique of what is superfluous\")\n",
    "\n",
    "\n",
    "class AnswerQuestion(BaseModel):\n",
    "    \"\"\"Answer the question. Provide an answer, reflection, and then follow up with search queries to improve the answer.\"\"\"\n",
    "\n",
    "    answer: str = Field(description=\"~250 word detailed answer to the question.\")\n",
    "    reflection: Reflection = Field(description=\"Your reflection on the initial answer.\")\n",
    "    search_queries: list[str] = Field(\n",
    "        description=\"1-3 search queries for researching improvements to address the critique of your current answer.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ResponderWithRetries:\n",
    "    def __init__(self, runnable, validator):\n",
    "        self.runnable = runnable\n",
    "        self.validator = validator\n",
    "\n",
    "    def respond(self, state: dict):\n",
    "        response = []\n",
    "        for attempt in range(3):\n",
    "            response = self.runnable.invoke(\n",
    "                {\"messages\": state[\"messages\"]}, {\"tags\": [f\"attempt:{attempt}\"]}\n",
    "            )\n",
    "            try:\n",
    "                self.validator.invoke(response)\n",
    "                return {\"messages\": response}\n",
    "            except ValidationError as e:\n",
    "                state = state + [\n",
    "                    response,\n",
    "                    ToolMessage(\n",
    "                        content=f\"{repr(e)}\\n\\nPay close attention to the function schema.\\n\\n\"\n",
    "                        + self.validator.schema_json()\n",
    "                        + \" Respond by fixing all validation errors.\",\n",
    "                        tool_call_id=response.tool_calls[0][\"id\"],\n",
    "                    ),\n",
    "                ]\n",
    "        return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5951c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "actor_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are expert researcher.\n",
    "Current time: {time}\n",
    "\n",
    "1. {first_instruction}\n",
    "2. Reflect and critique your answer. Be severe to maximize improvement.\n",
    "3. Recommend search queries to research information and improve your answer.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"\\n\\n<system>Reflect on the user's original question and the\"\n",
    "            \" actions taken thus far. Respond using the {function_name} function.</reminder>\",\n",
    "        ),\n",
    "    ]\n",
    ").partial(\n",
    "    time=lambda: datetime.datetime.now().isoformat(),\n",
    ")\n",
    "initial_answer_chain = actor_prompt_template.partial(\n",
    "    first_instruction=\"Provide a detailed ~250 word answer.\",\n",
    "    function_name=AnswerQuestion.__name__,\n",
    ") | llm.bind_tools(tools=[AnswerQuestion])\n",
    "validator = PydanticToolsParser(tools=[AnswerQuestion])\n",
    "\n",
    "first_responder = ResponderWithRetries(\n",
    "    runnable=initial_answer_chain, validator=validator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36e8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_question = \"Why is reflection useful in AI?\"\n",
    "initial = first_responder.respond(\n",
    "    {\"messages\": [HumanMessage(content=example_question)]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380a4607",
   "metadata": {},
   "source": [
    "#### 수정 단계\n",
    "\n",
    "액터의 두 번째 단계는 답변을 수정하는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f16dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "revise_instructions = \"\"\"새로운 정보를 활용해 이전 답변을 수정하세요.\n",
    "    - 이전 비판을 활용하여 중요한 정보를 추가합니다.\n",
    "        - 수정된 답변에는 검증이 가능하도록 반드시 번호가 매겨진 인용을 포함해야 합니다.\n",
    "        - 답변 하단에 \"References\" 섹션을 추가합니다(단어 수에 포함되지 않음). 예시 형식:\n",
    "            - [1] https://example.com\n",
    "            - [2] https://example.com\n",
    "    - 이전 비판을 참고하여 불필요한 정보를 제거하고, 답변이 250단어를 넘지 않도록 하세요.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Extend the initial answer schema to include references.\n",
    "# Forcing citation in the model encourages grounded responses\n",
    "class ReviseAnswer(AnswerQuestion):\n",
    "    \"\"\"Revise your original answer to your question. Provide an answer, reflection,\n",
    "\n",
    "    cite your reflection with references, and finally\n",
    "    add search queries to improve the answer.\"\"\"\n",
    "\n",
    "    references: list[str] = Field(\n",
    "        description=\"Citations motivating your updated answer.\"\n",
    "    )\n",
    "\n",
    "\n",
    "revision_chain = actor_prompt_template.partial(\n",
    "    first_instruction=revise_instructions,\n",
    "    function_name=ReviseAnswer.__name__,\n",
    ") | llm.bind_tools(tools=[ReviseAnswer])\n",
    "revision_validator = PydanticToolsParser(tools=[ReviseAnswer])\n",
    "\n",
    "revisor = ResponderWithRetries(runnable=revision_chain, validator=revision_validator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207e7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "revised = revisor.respond(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=example_question),\n",
    "            initial[\"messages\"],\n",
    "            ToolMessage(\n",
    "                tool_call_id=initial[\"messages\"].tool_calls[0][\"id\"],\n",
    "                content=json.dumps(\n",
    "                    tavily_tool.invoke(\n",
    "                        {\n",
    "                            \"query\": initial[\"messages\"].tool_calls[0][\"args\"][\n",
    "                                \"search_queries\"\n",
    "                            ][0]\n",
    "                        }\n",
    "                    )\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "revised[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b1d74",
   "metadata": {},
   "source": [
    "## 도구 노드 만들기\n",
    "\n",
    "다음으로 도구 호출을 실행할 노드를 만듭니다. LLM마다 서로 다른 스키마 이름을 사용하지만(검증에도 활용), 실제로는 동일한 도구로 연결되도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ee3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def run_queries(search_queries: list[str], **kwargs):\n",
    "    \"\"\"Run the generated queries.\"\"\"\n",
    "    return tavily_tool.batch([{\"query\": query} for query in search_queries])\n",
    "\n",
    "\n",
    "tool_node = ToolNode(\n",
    "    [\n",
    "        StructuredTool.from_function(run_queries, name=AnswerQuestion.__name__),\n",
    "        StructuredTool.from_function(run_queries, name=ReviseAnswer.__name__),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1633b920",
   "metadata": {},
   "source": [
    "## 그래프 구성\n",
    "\n",
    "\n",
    "이제 모든 구성 요소를 하나로 연결해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0927b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "MAX_ITERATIONS = 5\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"draft\", first_responder.respond)\n",
    "\n",
    "\n",
    "builder.add_node(\"execute_tools\", tool_node)\n",
    "builder.add_node(\"revise\", revisor.respond)\n",
    "# draft -> execute_tools\n",
    "builder.add_edge(\"draft\", \"execute_tools\")\n",
    "# execute_tools -> revise\n",
    "builder.add_edge(\"execute_tools\", \"revise\")\n",
    "\n",
    "# Define looping logic:\n",
    "\n",
    "\n",
    "def _get_num_iterations(state: list):\n",
    "    i = 0\n",
    "    for m in state[::-1]:\n",
    "        if m.type not in {\"tool\", \"ai\"}:\n",
    "            break\n",
    "        i += 1\n",
    "    return i\n",
    "\n",
    "\n",
    "def event_loop(state: list):\n",
    "    # in our case, we'll just stop after N plans\n",
    "    num_iterations = _get_num_iterations(state[\"messages\"])\n",
    "    if num_iterations > MAX_ITERATIONS:\n",
    "        return END\n",
    "    return \"execute_tools\"\n",
    "\n",
    "\n",
    "# revise -> execute_tools OR end\n",
    "builder.add_conditional_edges(\"revise\", event_loop, [\"execute_tools\", END])\n",
    "builder.add_edge(START, \"draft\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3017ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78efd20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"How should we handle the climate crisis?\")]},\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for i, step in enumerate(events):\n",
    "    print(f\"Step {i}\")\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5766e7",
   "metadata": {},
   "source": [
    "## 마무리\n",
    "\n",
    "리플렉션 액터를 구축하느라 수고하셨습니다! 워크플로에 어떤 부분을 적용할지 결정할 때 도움이 될 만한 몇 가지 관찰을 남겨드립니다.\n",
    "1. 이 에이전트는 실행 시간과 품질을 맞바꾸는 구조입니다. 여러 단계를 거치며 스스로를 비판하고 수정하도록 강제하기 때문에 보통(항상은 아니지만) 응답 품질이 향상되지만 최종 답변이 나오기까지 시간이 더 오래 걸립니다.\n",
    "2. 이러한 \"반성\" 단계는 검증기와 같은 추가 외부 피드백과 결합하여 액터를 더 효과적으로 안내할 수 있습니다.\n",
    "3. 논문에서 한 환경(AlfWorld)은 외부 메모리를 사용합니다. 반성 내용을 요약해 외부 저장소에 보관한 뒤, 이후 시도나 호출에서 이를 활용합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
